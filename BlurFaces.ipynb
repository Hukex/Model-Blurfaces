{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 FACEs, 12.1ms\n",
      "Speed: 7.4ms preprocess, 12.1ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"model.pt\")\n",
    "\n",
    "image_path = \"foto.png\"\n",
    "im2 = cv2.imread(image_path)\n",
    "\n",
    "results = model.predict(source=im2, save=False, save_txt=False)\n",
    "\n",
    "img_all_blurred = cv2.medianBlur(im2, 25)\n",
    "\n",
    "mask_img = np.zeros(im2.shape, dtype='uint8')\n",
    "for box in results[0].boxes:\n",
    "    x_min, y_min, x_max, y_max = map(int, box.xyxy.tolist()[0])\n",
    "    w, h = x_max - x_min, y_max - y_min\n",
    "    ellipse_center = ((x_min + x_max) // 2, (y_min + y_max) // 2)\n",
    "    axes = (w // 2, h // 2)\n",
    "    cv2.ellipse(mask_img, ellipse_center, axes, 0, 0, 360, (255, 255, 255), -1)\n",
    "\n",
    "im2 = np.where(mask_img > 0, img_all_blurred, im2)\n",
    "\n",
    "base_name, ext = os.path.splitext(image_path)\n",
    "output_path = f\"{base_name}_blurred{ext}\"\n",
    "\n",
    "cv2.imwrite(output_path, im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 5 FACEs, 24.6ms\n",
      "Speed: 4.8ms preprocess, 24.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"model.pt\")\n",
    "\n",
    "image_path = \"foto.png\"\n",
    "im2 = cv2.imread(image_path)\n",
    "\n",
    "results = model.predict(source=im2, save=False, save_txt=False)\n",
    "\n",
    "def pixelate_region(image, x_min, y_min, x_max, y_max, pixel_size=10):\n",
    "    # Crop the region of interest\n",
    "    roi = image[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "    # Resize to a smaller size\n",
    "    temp = cv2.resize(roi, (pixel_size, pixel_size), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # Resize back to the original size\n",
    "    pixelated = cv2.resize(temp, (x_max - x_min, y_max - y_min), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Replace the region with the pixelated version\n",
    "    image[y_min:y_max, x_min:x_max] = pixelated\n",
    "    return image\n",
    "\n",
    "# Create an empty mask with the same size as the image\n",
    "mask_img = np.zeros(im2.shape, dtype='uint8')\n",
    "\n",
    "for box in results[0].boxes:\n",
    "    x_min, y_min, x_max, y_max = map(int, box.xyxy.tolist()[0])\n",
    "    im2 = pixelate_region(im2, x_min, y_min, x_max, y_max, pixel_size=10)\n",
    "\n",
    "base_name, ext = os.path.splitext(image_path)\n",
    "output_path = f\"{base_name}_pixelated{ext}\"\n",
    "\n",
    "cv2.imwrite(output_path, im2)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo YOLO cargado correctamente.\n",
      "Modelo de clasificación cargado correctamente.\n",
      "Imagen cargada correctamente.\n",
      "\n",
      "0: 384x640 5 FACEs, 13.5ms\n",
      "Speed: 0.0ms preprocess, 13.5ms inference, 15.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Detecciones YOLO: 5 caras detectadas.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 449ms/step\n",
      "Predicción: 0.0817958265542984, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicción: 0.13366596400737762, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predicción: 0.041347015649080276, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicción: 0.02121875248849392, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicción: 0.027821630239486694, Es menor: False\n",
      "Imagen guardada en foto_blurred.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "\n",
    "yolo_model = YOLO(\"model.pt\")\n",
    "print(\"Modelo YOLO cargado correctamente.\")\n",
    "\n",
    "classification_model = tf.keras.models.load_model(\"model_lr_0.0001_batch_16_batchnorm_True.h5\")\n",
    "print(\"Modelo de clasificación cargado correctamente.\")\n",
    "\n",
    "img_height = 200\n",
    "img_width = 200\n",
    "\n",
    "def preprocess_image(img, save_path=None):\n",
    "    img_resized = cv2.resize(img, (img_width, img_height))\n",
    "    img_normalized = img_resized.astype('float32') / 255.0\n",
    "    img_expanded = np.expand_dims(img_normalized, axis=0)\n",
    "    \n",
    "    if save_path:\n",
    "        cv2.imwrite(save_path, (img_normalized * 255).astype('uint8'))\n",
    "    \n",
    "    return img_expanded\n",
    "\n",
    "image_path = \"foto.png\"\n",
    "im2 = cv2.imread(image_path)\n",
    "if im2 is not None:\n",
    "    print(\"Imagen cargada correctamente.\")\n",
    "else:\n",
    "    print(\"Error al cargar la imagen.\")\n",
    "\n",
    "base_name, ext = os.path.splitext(image_path)\n",
    "preprocessed_dir = f\"{base_name}_preprocessed\"\n",
    "os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "\n",
    "results = yolo_model.predict(source=im2, save=False, save_txt=False)\n",
    "print(f\"Detecciones YOLO: {len(results[0].boxes)} caras detectadas.\")\n",
    "\n",
    "img_all_blurred = cv2.medianBlur(im2, 25)\n",
    "\n",
    "# Crear una máscara para las áreas que necesitan desenfoque\n",
    "mask_img = np.zeros(im2.shape, dtype='uint8')\n",
    "\n",
    "for i, box in enumerate(results[0].boxes):\n",
    "    x_min, y_min, x_max, y_max = map(int, box.xyxy.tolist()[0])\n",
    "    face_img = im2[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "    preprocessed_face_path = os.path.join(preprocessed_dir, f\"preprocessed_face_{i}.png\")\n",
    "    preprocessed_face = preprocess_image(face_img, save_path=preprocessed_face_path)\n",
    "    print(f\"Preprocessed face {i} shape: {preprocessed_face.shape}\")\n",
    "    \n",
    "    prediction = classification_model.predict(preprocessed_face)\n",
    "    is_minor = prediction[0][0] > 0.4 \n",
    "    \n",
    "    print(f\"Predicción: {prediction[0][0]}, Es menor: {is_minor}\")\n",
    "    \n",
    "    if is_minor:\n",
    "        w, h = x_max - x_min, y_max - y_min\n",
    "        ellipse_center = ((x_min + x_max) // 2, (y_min + y_max) // 2)\n",
    "        axes = (w // 2, h // 2)\n",
    "        cv2.ellipse(mask_img, ellipse_center, axes, 0, 0, 360, (255, 255, 255), -1)\n",
    "\n",
    "im2 = np.where(mask_img > 0, img_all_blurred, im2)\n",
    "\n",
    "output_path = f\"{base_name}_blurred{ext}\"\n",
    "\n",
    "cv2.imwrite(output_path, im2)\n",
    "print(f\"Imagen guardada en {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo YOLO cargado correctamente.\n",
      "Imagen cargada correctamente.\n",
      "\n",
      "0: 448x640 8 FACEs, 154.0ms\n",
      "Speed: 15.6ms preprocess, 154.0ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Detecciones YOLO: 8 caras detectadas.\n",
      "Cargando model_lr_0.01_batch_16_batchnorm_True.h5...\n",
      "Modelo model_lr_0.01_batch_16_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 354ms/step\n",
      "Predicción: 0.22842366993427277, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicción: 0.3182843327522278, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicción: 0.30062946677207947, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.18349306285381317, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.25276368856430054, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.11873257160186768, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Predicción: 0.27682268619537354, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Predicción: 0.24181924760341644, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.01_batch_16_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.001_batch_16_batchnorm_True.h5...\n",
      "Modelo model_lr_0.001_batch_16_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 331ms/step\n",
      "Predicción: 0.006246141158044338, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicción: 0.06666333228349686, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicción: 0.01831388659775257, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Predicción: 0.042062561959028244, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Predicción: 0.23619991540908813, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicción: 0.009484050795435905, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predicción: 0.0873878002166748, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicción: 0.04312136396765709, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.001_batch_16_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.0005_batch_16_batchnorm_True.h5...\n",
      "Modelo model_lr_0.0005_batch_16_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 289ms/step\n",
      "Predicción: 0.06159346550703049, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predicción: 0.0252253245562315, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.028291523456573486, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.014532840810716152, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.10451705008745193, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.19391347467899323, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicción: 0.032735615968704224, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicción: 0.02118493802845478, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0005_batch_16_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.0001_batch_16_batchnorm_True.h5...\n",
      "Modelo model_lr_0.0001_batch_16_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "Predicción: 0.010651867836713791, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicción: 0.05689093843102455, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.021872879937291145, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicción: 0.08288983255624771, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicción: 0.02988710068166256, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicción: 0.011205977760255337, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Predicción: 0.040541794151067734, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicción: 0.048285480588674545, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0001_batch_16_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.01_batch_32_batchnorm_True.h5...\n",
      "Modelo model_lr_0.01_batch_32_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 307ms/step\n",
      "Predicción: 0.307041198015213, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predicción: 0.2023436725139618, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicción: 0.20263329148292542, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.16009964048862457, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.1967773586511612, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Predicción: 0.3059680461883545, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "Predicción: 0.18473924696445465, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Predicción: 0.14605844020843506, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.01_batch_32_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.001_batch_32_batchnorm_True.h5...\n",
      "Modelo model_lr_0.001_batch_32_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 325ms/step\n",
      "Predicción: 0.07503554224967957, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Predicción: 0.0806661993265152, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicción: 0.06135009229183197, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicción: 0.08821732550859451, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "Predicción: 0.08091853559017181, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicción: 0.05702938139438629, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predicción: 0.09717421978712082, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicción: 0.09953639656305313, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.001_batch_32_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.0005_batch_32_batchnorm_True.h5...\n",
      "Modelo model_lr_0.0005_batch_32_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 346ms/step\n",
      "Predicción: 0.051425863057374954, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Predicción: 0.08041619509458542, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Predicción: 0.07145215570926666, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicción: 0.09571737796068192, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Predicción: 0.09249202907085419, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicción: 0.09337896853685379, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicción: 0.09148772805929184, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicción: 0.0722678080201149, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0005_batch_32_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.0001_batch_32_batchnorm_True.h5...\n",
      "Modelo model_lr_0.0001_batch_32_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 337ms/step\n",
      "Predicción: 0.01651834324002266, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.1386554092168808, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Predicción: 0.05747424066066742, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predicción: 0.20261234045028687, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Predicción: 0.05397038161754608, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicción: 0.033126406371593475, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Predicción: 0.07621089369058609, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.1331067532300949, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0001_batch_32_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.01_batch_64_batchnorm_True.h5...\n",
      "Modelo model_lr_0.01_batch_64_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 338ms/step\n",
      "Predicción: 0.1258108764886856, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicción: 0.0780218094587326, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Predicción: 0.06394602358341217, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Predicción: 0.06631425023078918, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicción: 0.11072384566068649, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Predicción: 0.15848994255065918, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.0644531175494194, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.06692522019147873, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.01_batch_64_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.001_batch_64_batchnorm_True.h5...\n",
      "Modelo model_lr_0.001_batch_64_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "Predicción: 0.10329613089561462, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predicción: 0.11640875786542892, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "Predicción: 0.1601957231760025, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predicción: 0.1175713911652565, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicción: 0.12274797260761261, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.06114949285984039, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicción: 0.08409371972084045, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predicción: 0.13859882950782776, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.001_batch_64_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.0005_batch_64_batchnorm_True.h5...\n",
      "Modelo model_lr_0.0005_batch_64_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 326ms/step\n",
      "Predicción: 0.029175467789173126, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "Predicción: 0.04574722424149513, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicción: 0.05210435017943382, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicción: 0.04712812975049019, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicción: 0.11142977327108383, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predicción: 0.06473828852176666, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predicción: 0.04712309688329697, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "Predicción: 0.05035572871565819, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0005_batch_64_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.0001_batch_64_batchnorm_True.h5...\n",
      "Modelo model_lr_0.0001_batch_64_batchnorm_True cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 327ms/step\n",
      "Predicción: 0.0092725595459342, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "Predicción: 0.047762952744960785, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Predicción: 0.02874552085995674, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicción: 0.08124641329050064, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Predicción: 0.029000133275985718, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicción: 0.002406128915026784, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Predicción: 0.01673325151205063, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.04077671468257904, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0001_batch_64_batchnorm_True_blurred.png\n",
      "Cargando model_lr_0.01_batch_16_batchnorm_False.h5...\n",
      "Modelo model_lr_0.01_batch_16_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 245ms/step\n",
      "Predicción: 0.39662668108940125, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.39662668108940125, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicción: 0.39662668108940125, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Predicción: 0.39662668108940125, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.39662668108940125, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.39662668108940125, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "Predicción: 0.39662668108940125, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicción: 0.39662668108940125, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.01_batch_16_batchnorm_False_blurred.png\n",
      "Cargando model_lr_0.001_batch_16_batchnorm_False.h5...\n",
      "Modelo model_lr_0.001_batch_16_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 171ms/step\n",
      "Predicción: 0.22171953320503235, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicción: 0.37007975578308105, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicción: 0.034585945308208466, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "Predicción: 0.129011332988739, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.280986487865448, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicción: 0.4055371880531311, Es menor: True\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.2614710032939911, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "Predicción: 0.09492745995521545, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.001_batch_16_batchnorm_False_blurred.png\n",
      "Cargando model_lr_0.0005_batch_16_batchnorm_False.h5...\n",
      "Modelo model_lr_0.0005_batch_16_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 212ms/step\n",
      "Predicción: 0.13780228793621063, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predicción: 0.5265205502510071, Es menor: True\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Predicción: 0.1808861792087555, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicción: 0.18925288319587708, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predicción: 0.04093474894762039, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.014165112748742104, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicción: 0.11871370673179626, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.2468603253364563, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0005_batch_16_batchnorm_False_blurred.png\n",
      "Cargando model_lr_0.0001_batch_16_batchnorm_False.h5...\n",
      "Modelo model_lr_0.0001_batch_16_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 169ms/step\n",
      "Predicción: 0.10587359219789505, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicción: 0.6498973965644836, Es menor: True\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicción: 0.23637755215168, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicción: 0.19365958869457245, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "Predicción: 0.08899199962615967, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "Predicción: 0.07195769250392914, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicción: 0.3315035402774811, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.31164810061454773, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0001_batch_16_batchnorm_False_blurred.png\n",
      "Cargando model_lr_0.01_batch_32_batchnorm_False.h5...\n",
      "Modelo model_lr_0.01_batch_32_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 178ms/step\n",
      "Predicción: 0.39910343289375305, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.39910343289375305, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.39910343289375305, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Predicción: 0.39910343289375305, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicción: 0.39910343289375305, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.39910343289375305, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.39910343289375305, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Predicción: 0.39910343289375305, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.01_batch_32_batchnorm_False_blurred.png\n",
      "Cargando model_lr_0.001_batch_32_batchnorm_False.h5...\n",
      "Modelo model_lr_0.001_batch_32_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 194ms/step\n",
      "Predicción: 0.36040198802948, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicción: 0.32989487051963806, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predicción: 0.29444244503974915, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.15535438060760498, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.12931233644485474, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicción: 0.1943892240524292, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicción: 0.296426385641098, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicción: 0.19014118611812592, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.001_batch_32_batchnorm_False_blurred.png\n",
      "Cargando model_lr_0.0005_batch_32_batchnorm_False.h5...\n",
      "Modelo model_lr_0.0005_batch_32_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "Predicción: 0.5958906412124634, Es menor: True\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicción: 0.6063597202301025, Es menor: True\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicción: 0.46730610728263855, Es menor: True\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Predicción: 0.3236536979675293, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicción: 0.35170766711235046, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.4794164299964905, Es menor: True\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.5071003437042236, Es menor: True\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.413814514875412, Es menor: True\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0005_batch_32_batchnorm_False_blurred.png\n",
      "Cargando model_lr_0.0001_batch_32_batchnorm_False.h5...\n",
      "Modelo model_lr_0.0001_batch_32_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Predicción: 0.1018320694565773, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.19341211020946503, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicción: 0.2624039947986603, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "Predicción: 0.14703229069709778, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicción: 0.05037641525268555, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicción: 0.14073674380779266, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicción: 0.1906549483537674, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "Predicción: 0.10893195122480392, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0001_batch_32_batchnorm_False_blurred.png\n",
      "Cargando model_lr_0.01_batch_64_batchnorm_False.h5...\n",
      "Modelo model_lr_0.01_batch_64_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 168ms/step\n",
      "Predicción: 0.39763423800468445, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "Predicción: 0.39763423800468445, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Predicción: 0.39763423800468445, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicción: 0.39763423800468445, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.39763423800468445, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicción: 0.39763423800468445, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Predicción: 0.39763423800468445, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Predicción: 0.39763423800468445, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.01_batch_64_batchnorm_False_blurred.png\n",
      "Cargando model_lr_0.001_batch_64_batchnorm_False.h5...\n",
      "Modelo model_lr_0.001_batch_64_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 208ms/step\n",
      "Predicción: 0.222195565700531, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicción: 0.19379539787769318, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicción: 0.21912261843681335, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Predicción: 0.22919528186321259, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "Predicción: 0.12060585618019104, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.15673044323921204, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Predicción: 0.11486616730690002, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicción: 0.2064981460571289, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.001_batch_64_batchnorm_False_blurred.png\n",
      "Cargando model_lr_0.0005_batch_64_batchnorm_False.h5...\n",
      "Modelo model_lr_0.0005_batch_64_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 150ms/step\n",
      "Predicción: 0.2611048221588135, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicción: 0.30076006054878235, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicción: 0.21445731818675995, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicción: 0.21899919211864471, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "Predicción: 0.1810177117586136, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Predicción: 0.25391390919685364, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Predicción: 0.3202309310436249, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Predicción: 0.2522488236427307, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0005_batch_64_batchnorm_False_blurred.png\n",
      "Cargando model_lr_0.0001_batch_64_batchnorm_False.h5...\n",
      "Modelo model_lr_0.0001_batch_64_batchnorm_False cargado correctamente.\n",
      "Preprocessed face 0 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "Predicción: 0.10362859815359116, Es menor: False\n",
      "Preprocessed face 1 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "Predicción: 0.27101844549179077, Es menor: False\n",
      "Preprocessed face 2 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "Predicción: 0.18451610207557678, Es menor: False\n",
      "Preprocessed face 3 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "Predicción: 0.20641964673995972, Es menor: False\n",
      "Preprocessed face 4 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicción: 0.04635254666209221, Es menor: False\n",
      "Preprocessed face 5 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Predicción: 0.03700558841228485, Es menor: False\n",
      "Preprocessed face 6 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Predicción: 0.21067588031291962, Es menor: False\n",
      "Preprocessed face 7 shape: (1, 200, 200, 3)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Predicción: 0.1671033799648285, Es menor: False\n",
      "Imagen guardada en foto3_outputs\\foto3_model_lr_0.0001_batch_64_batchnorm_False_blurred.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "\n",
    "# Cargar modelo YOLO\n",
    "yolo_model = YOLO(\"model.pt\")\n",
    "print(\"Modelo YOLO cargado correctamente.\")\n",
    "\n",
    "# Lista de modelos de clasificación\n",
    "model_names = [\n",
    "    \"model_lr_0.01_batch_16_batchnorm_True\",\n",
    "    \"model_lr_0.001_batch_16_batchnorm_True\",\n",
    "    \"model_lr_0.0005_batch_16_batchnorm_True\",\n",
    "    \"model_lr_0.0001_batch_16_batchnorm_True\",\n",
    "    \"model_lr_0.01_batch_32_batchnorm_True\",\n",
    "    \"model_lr_0.001_batch_32_batchnorm_True\",\n",
    "    \"model_lr_0.0005_batch_32_batchnorm_True\",\n",
    "    \"model_lr_0.0001_batch_32_batchnorm_True\",\n",
    "    \"model_lr_0.01_batch_64_batchnorm_True\",\n",
    "    \"model_lr_0.001_batch_64_batchnorm_True\",\n",
    "    \"model_lr_0.0005_batch_64_batchnorm_True\",\n",
    "    \"model_lr_0.0001_batch_64_batchnorm_True\",\n",
    "    \"model_lr_0.01_batch_16_batchnorm_False\",\n",
    "    \"model_lr_0.001_batch_16_batchnorm_False\",\n",
    "    \"model_lr_0.0005_batch_16_batchnorm_False\",\n",
    "    \"model_lr_0.0001_batch_16_batchnorm_False\",\n",
    "    \"model_lr_0.01_batch_32_batchnorm_False\",\n",
    "    \"model_lr_0.001_batch_32_batchnorm_False\",\n",
    "    \"model_lr_0.0005_batch_32_batchnorm_False\",\n",
    "    \"model_lr_0.0001_batch_32_batchnorm_False\",\n",
    "    \"model_lr_0.01_batch_64_batchnorm_False\",\n",
    "    \"model_lr_0.001_batch_64_batchnorm_False\",\n",
    "    \"model_lr_0.0005_batch_64_batchnorm_False\",\n",
    "    \"model_lr_0.0001_batch_64_batchnorm_False\"\n",
    "]\n",
    "\n",
    "# Configuración de la imagen\n",
    "img_height = 200\n",
    "img_width = 200\n",
    "\n",
    "def preprocess_image(img, save_path=None):\n",
    "    img_resized = cv2.resize(img, (img_width, img_height))\n",
    "    img_normalized = img_resized.astype('float32') / 255.0\n",
    "    img_expanded = np.expand_dims(img_normalized, axis=0)\n",
    "    \n",
    "    if save_path:\n",
    "        cv2.imwrite(save_path, (img_normalized * 255).astype('uint8'))\n",
    "    \n",
    "    return img_expanded\n",
    "\n",
    "image_path = \"foto3.png\"\n",
    "im2 = cv2.imread(image_path)\n",
    "if im2 is not None:\n",
    "    print(\"Imagen cargada correctamente.\")\n",
    "else:\n",
    "    print(\"Error al cargar la imagen.\")\n",
    "\n",
    "base_name, ext = os.path.splitext(image_path)\n",
    "preprocessed_dir = f\"{base_name}_preprocessed\"\n",
    "output_dir = f\"{base_name}_outputs\"\n",
    "os.makedirs(preprocessed_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "results = yolo_model.predict(source=im2, save=False, save_txt=False)\n",
    "print(f\"Detecciones YOLO: {len(results[0].boxes)} caras detectadas.\")\n",
    "\n",
    "# Iterar sobre todos los modelos y realizar predicciones\n",
    "for model_name in model_names:\n",
    "    model_path = f\"{model_name}.h5\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Cargando {model_path}...\")\n",
    "        classification_model = tf.keras.models.load_model(model_path)\n",
    "        print(f\"Modelo {model_name} cargado correctamente.\")\n",
    "\n",
    "        img_all_blurred = cv2.medianBlur(im2, 25)\n",
    "        mask_img = np.zeros(im2.shape, dtype='uint8')\n",
    "\n",
    "        for i, box in enumerate(results[0].boxes):\n",
    "            x_min, y_min, x_max, y_max = map(int, box.xyxy.tolist()[0])\n",
    "            face_img = im2[y_min:y_max, x_min:x_max]\n",
    "            \n",
    "            preprocessed_face_path = os.path.join(preprocessed_dir, f\"preprocessed_face_{i}.png\")\n",
    "            preprocessed_face = preprocess_image(face_img, save_path=preprocessed_face_path)\n",
    "            print(f\"Preprocessed face {i} shape: {preprocessed_face.shape}\")\n",
    "            \n",
    "            prediction = classification_model.predict(preprocessed_face)\n",
    "            is_minor = prediction[0][0] > 0.4 \n",
    "            \n",
    "            print(f\"Predicción: {prediction[0][0]}, Es menor: {is_minor}\")\n",
    "            \n",
    "            if is_minor:\n",
    "                w, h = x_max - x_min, y_max - y_min\n",
    "                ellipse_center = ((x_min + x_max) // 2, (y_min + y_max) // 2)\n",
    "                axes = (w // 2, h // 2)\n",
    "                cv2.ellipse(mask_img, ellipse_center, axes, 0, 0, 360, (255, 255, 255), -1)\n",
    "\n",
    "        final_image = np.where(mask_img > 0, img_all_blurred, im2)\n",
    "        output_path = os.path.join(output_dir, f\"{base_name}_{model_name}_blurred{ext}\")\n",
    "\n",
    "        cv2.imwrite(output_path, final_image)\n",
    "        print(f\"Imagen guardada en {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blurfaces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
